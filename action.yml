name: 'evaluate benchmark'
description: 'Evaluate benchmark results'

inputs:
  folder_with_bench_data:
    description: |
      The file serves as the repository for both historical benchmark data
      and the location where new benchmark data will be appended.
      Currently, only .js files are supported.
    required: false
    default: 'bench_data'
  file_with_bench_data:
    description: |
      The name of the file that contains the benchmark data.
      Currently, only .js files are supported.
    required: false
    default: 'data.json'
  folder_with_current_benchmark_results:
    description: |
      A path to the folder where benchmark results are stored.
      Can be a single file or multiple files.
    required: true

  name:
    description: 'The name of a specific benchmark. This name will be used to identify the benchmark ...'
    required: false
    default: 'Benchmark'
  result_files_merge_strategy_for_each_metric:
    description: |
      The strategy to use when merging the the benchmark results from the downloaded folder.
      This should be a comma separated list of strategies. Each strategy corresponds to a metric.
      The possible values are: sum, average, max, min, median.
    required: false
  metrics_to_evaluate:
    description: |
      A comma-separated list of metrics to evaluate for the current benchmark.
      This must be a subset of metrics from the file pointed to by current_bench_res_file.
      If not specified, all metrics will be evaluated.
    required: false
  github_token:
    description: 'GitHub token to pull/push to repo, add benchmark info to the repo, etc.'
    required: false
  comment_to_commit:
    description: |
      Add commit comment with the detailed benchmark info.
      Possible values are on, off, if_failed.
    required: false
    default: "if_failed"
  alert_users_if_bench_failed:
    description: |
      Commas-separated list of users to alert if the benchmark failed.
    required: false
  action_page_job_summary:
    description: 'Leave a short summary on the workflow page. Possible values are on, off, if_failed'
    required: false
    default: "on"
  save_curr_bench_res:
    description: |
      Save the benchmark data pointed to by current_bench_res_file
      to a file located in benchmark_data_file'
    required: false
    default: "true"
  evaluation_method:
    description: |
      It refers to a reference point by which we determine whether the benchmark is successful or not.
      The possible values are 'previous', 'previous_successful', 'threshold', 'jump_detection', 'trend_detection_moving_ave',
      'trend_detection_deltas'
    required: true
  bench_to_compare:
    description: |
      The name of the benchmark to compare to.
      This input is only used when the reference is set to 'previous' or 'previous_successful.'
      If not specified, the benchmark with the same name as the current benchmark is used.
    required: false
  threshold_values:
    description: 'Comma-separated list of threshold values for comparison.'
    required: false
  comparison_operators:
    description: 'Comma-separated list of operators for threshold comparison.'
    required: false
  comparison_margins:
    description: |
      Describes by how much percentage a given value can deviate from the desired
      value (threshold or prev) to still qualify the benchmark as successful.
      If you have selected range as one of the modes in the above set of modes,
      and it is not the only function, please provide values of -1 for the remaining functions.
      For example, if you previously entered: smaller, smaller, range, and your range is 20%,
      this input should look as follows: "-1, -1, 20"
  threshold_upper:
    description: 'Comma-separated list of upper threshold values for range comparison.'
    required: false
  threshold_lower:
    description: 'Comma-separated list of lower threshold values for range comparison.'
    required: false
  jump_detection_thresholds:
    description: 'The threshold values for jump detection.'
    required: false
  trend_thresholds:
    description: 'The threshold value for both deltas trend detection and moving average.'
    required: false
  moving_ave_window_size:
    description: 'The window size for moving average trend detection.'
    required: false
  trend_det_no_sufficient_data_strategy:
    description: | 
      The strategy to use when there is not enough data to perform trend detection.
      The possible values are use_available and fail.
    required: false
    default: "use_available"
  trend_det_successful_release_branch:
    description: |
      The name of the branch that contains the successful benchmark result
      in a release branch.
      If not specified, main branch will be used.
    required: false
    default: "main"
  failing_condition:
    description: |
      Specifies when the benchmark should fail.
      The possible values are any, all, and none.
    required: false
    default: "any"
  link_to_templated_gh_page_with_results:
    description: |
      The link to the GitHub page with the benchmark results.
      The link should be templated with the benchmark name.
      For example, if the benchmark name is 'Benchmark', the link should look as follows:
      https://dawidniezgodka.github.io/Bench1-Final/
    required: false

outputs:
  should_fail:
    description: |
      Indicates whether the benchmark should fail or not.
      The possible values are true and false.

runs:
  using: node20
  main: dist/index.js
